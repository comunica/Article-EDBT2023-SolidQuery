<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title property="foaf:name schema:name">Evaluation of Link Traversal Query Execution over Decentralized Environments with Structural Assumptions</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print"  href="styles/print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  <meta name="citation_title" content="Evaluation of Link Traversal Query Execution over Decentralized Environments with Structural Assumptions">
  <meta name="citation_author" content="John Doe" />
  
  <meta name="citation_publication_date" content="2022/08/25" />
</head>

<body prefix="dctypes: http://purl.org/dc/dcmitype/ pimspace: http://www.w3.org/ns/pim/space# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# lsc: http://linkedscience.org/lsc/ns#" typeof="schema:CreativeWork sioc:Post prov:Entity lsc:Research">
  <header>
  <h1 id="evaluation-of-link-traversal-query-execution-over-decentralized-environments-with-structural-assumptions">Evaluation of Link Traversal Query Execution over Decentralized Environments with Structural Assumptions</h1>

  <!--
{:#authors}
- <a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="http://www.example.org/" typeof="foaf:Person schema:Person" resource="http://www.example.org/#me">John Doe</a>

{:#affiliations}
- {:#myaffiliation} Awesome Inc.
-->

</header>

<!-- Hack to make our custom fonts load in print-mode -->
<!-- https://stackoverflow.com/questions/39364259/chrome-print-preview-doesnt-load-media-only-print-font-face -->
<p><span class="printfont1"> </span>
<span class="printfont2"> </span>
<span class="printfont3"> </span>
<span class="printfont4"> </span></p>

<div class="double-column">

<section id="abstract" inlist="" rel="schema:hasPart" resource="#abstract">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Abstract</h2>
      <!-- Context      -->
      <p>As a way to counter societal and economic problems with centralization,
decentralization efforts such as Solid lead to data being spread over a massive number of Linked Data documents on the Web.
This raises significant technical issues when querying over this data as if it was a global Knowledge Graph,
since this data can not be centralized due to legal reasons,
and current (federated) querying techniques have not been designed to handle this large scale of data distribution.
<!-- Need         -->
Hence, there is a need for an alternative query execution paradigm that can cope with such decentralized environments.
<!-- Task         -->
For this, we propose the use of Link Traversal Query Processing (LTQP) for querying over decentralized environments,
and extend it by making use of structural properties within these environments.
<!-- Object       -->
In this article,
we analyze the structural properties of the Solid decentralization ecosystem that are relevant for query execution,
and provide a benchmark in which Solid environments can be simulated.
Furthermore, we introduce LTQP algorithms based on these structural properties,
and evaluate its effectiveness.
<!-- Findings     -->
Our experiments show that …TODO…
<!-- Conclusion   -->
This works shows that a traversal-based querying method using structural assumptions is effective for querying over decentralized environments,
but that significant advances are needed in the area of query planning for LTQP.
<!-- Perspectives -->
This opens the window towards query-driven decentralized applications,
in which application developers interact with decentralized environments using declarative queries as if it was a single centralized database.</p>

      <p><span id="keywords" rel="schema:about"><span class="title">Keywords</span>
<a href="https://en.wikipedia.org/wiki/Linked_Data" resource="http://dbpedia.org/resource/Linked_Data">Linked Data</a>,
<a href="https://en.wikipedia.org/wiki/Resource_Description_Framework" resource="http://dbpedia.org/resource/Resource_Description_Framework">RDF</a>,
<a href="https://en.wikipedia.org/wiki/SPARQL" resource="http://dbpedia.org/resource/SPARQL">SPARQL</a>,
Link Traversal,
Solid
</span></p>

      <!--<span class="printonly" id="acmreferenceformat">
<span class="title">ACM Reference Format:</span>
Doe, J. My Awesome Article. In <i>Conference Companion: The Conference Companion, April 23—27, 2018, Lyon, France</i>. Publisher, New York, NY, USA, 4 pages.
<i>http:/​/​dx.doi.org/1.2/111.222</i>
</span>-->

      <p><span class="printonly firstpagefooter">
<span class="footnotecopyright">
This paper is published under the Creative Commons Attribution 4.0 International (CC-BY 4.0) license.
Authors reserve their rights to disseminate the work on their personal and corporate Web sites with the appropriate attribution.<br />
<span style="font-style:italic">CONFERENCE</span><br />
©2018 Copyright,
published under Creative Commons CC BY 4.0 License.<br />
Publisher 1122.<br />
DOI: http://dx.doi.org/1.2/111.222
</span>
</span></p>

    </div>
</section>


<main>
  <section id="introduction" inlist="" rel="schema:hasPart" resource="#introduction">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Introduction</h2>

        <p>Even though the Web has transformed our world to become more interconnected than before,
the Web is becoming increasingly centralized in recent years, contrary to its original vision <span class="references">[<a href="#ref-1">1</a>]</span>.
Today, the majority of data on the Web is flowing towards isolated <em>data silos</em>,
which are in the hands of large companies.
This siloization of data leads to a variety of problems,
ranging from issues with cross-silo interoperability and vendor lock-in
to privacy issues and the fact that data is in control by companies instead of users.</p>

        <p>Because of these reasons, and the introduction of user-empowering legislature such as GDPR and CCPA,
decentralization initiatives <span class="references">[<a href="#ref-2">2</a>, <a href="#ref-3">3</a>, <a href="#ref-4">4</a>]</span> are gaining popularity.
The common goal of these initiatives is
to give people back control over their own data
by decentralizing data on the Web instead of making use of centralized data silos.
Initiatives such as Solid <span class="references">[<a href="#ref-2">2</a>]</span> do this by allowing users to store any kind of data in their own personal data vault,
which are in full control by the users.
These data vaults form personal Knowledge Graphs <span class="references">[<a href="#ref-5">5</a>]</span>, which are represented as collections of <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.w3.org/DesignIssues/LinkedData.html">Linked Data documents</a> <span class="references">[<a href="#ref-6">6</a>]</span>.
The presence of such data vaults results in a massive distribution of data,
where practical cases such as social networking applications could require accessing thousands or even millions of documents
across different data vaults across the Web.
However, these applications can not yet be built today,
due to the lack of effective query execution techniques that are capable of handling the requirements of decentralized environments such as Solid.</p>

        <p>The majority of research in the domain of query execution over Knowledge Graphs has been focused on centralized use cases,
where all data is captured in just one or a small number of federated sources, usually exposed as <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.w3.org/TR/2013/REC-sparql11-protocol-20130321/">SPARQL endpoints</a> <span class="references">[<a href="#ref-7">7</a>]</span>.
Even though several federated query execution approaches have been introduced <span class="references">[<a href="#ref-8">8</a>, <a href="#ref-9">9</a>, <a href="#ref-10">10</a>]</span>,
they have been designed for federating over <em>a few (~10) large sources</em>,
while decentralized environments such as Solid are identified by <em>a large number (~millions) of small sources</em>.
Furthermore, federated query execution techniques assume all sources to be known prior to query execution,
which is not feasible in decentralized environments due to the lack of a centralized index.
Therefore, these federated querying techniques are currently not suitable for decentralized environments.</p>

        <p><em>Link Traversal Query Processing (LTQP)</em> <span class="references">[<a href="#ref-11">11</a>, <a href="#ref-12">12</a>]</span>
is an alternative query execution paradigm that is more promising for handling querying over large decentralized environments.
It is identified by its ability to query over a continuously growing range of documents which are discovered during query execution
by following hyperlinks between Linked Data documents using the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.w3.org/DesignIssues/LinkedData.html"><em>follow-your-nose</em> principle</a> <span class="references">[<a href="#ref-6">6</a>]</span>.
While LTQP has mainly been a theoretically interesting technique, it has not seen any practical use cases so far.</p>

        <p>In this work, we prove that LTQP is not only interesting in theory,
but that it is an effective paradigm for handling querying execution within large decentralized environments.
We do this by making use of specific structural properties within decentralized environments
that can be used for more effective source discovery and optimization of query execution.
We apply our research to the Solid ecosystem,
but these concepts are generalizable to other decentralization initiatives <span class="references">[<a href="#ref-3">3</a>, <a href="#ref-4">4</a>]</span>.
To the best of our knowledge, this is the first in-depth analysis of query execution within the Solid ecosystem.</p>

        <p>This article is structured as follows.
In the next section (<a href="#related-work">Section 2</a>), we discuss the related work,
after which we provide an analysis of the structural properties of Solid data vaults in <a href="#solid">Section 3</a>.
Next, in <a href="#benchmark">Section 4</a> we provide a benchmark that simulates a decentralized Solid environments based on this analysis.
In <a href="#approach">Section 5</a>, we introduce and explain LTQP algorithms that make use of these structural properties,
which are evaluated in <a href="#evaluation">Section 6</a>.
Finally, we conclude in <a href="#conclusions">Section 7</a>.</p>

        <!--
Contributions:
- Analysis of structural properties in solid pods
- SolidBench: Benchmark to simulate a Web of data with configurable structural axioms
- Guided link traversal algorithms for querying over Solid data vaults
- Implementation of existing (all?) and new algorithms
- An evaluation of link traversal algorithms within a simulated Web of Solid data vaults
{:.todo}
-->

      </div>
</section>

  <section id="related-work" inlist="" rel="schema:hasPart" resource="#related-work">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Related Work</h2>

        <p>In this section, we discuss the related work around Link Traversal Query Processing,
and related benchmarks for this paradigm.</p>

        <h3 id="link-traversal-query-processing">Link Traversal Query Processing</h3>

        <p>The Link Traversal Query Processing (LTQP) was introduced more than a decade ago <span class="references">[<a href="#ref-13">13</a>]</span>
as a way to query over the Web of Linked Data as if it was a single globally distributed dataspace,
without having to first indexing it in a single location.
LTQP does this by employing the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.w3.org/DesignIssues/LinkedData.html"><em>follow-your-nose</em> principle of Linked Data</a> <span class="references">[<a href="#ref-6">6</a>]</span> during query execution,
where new RDF triples are continuously added to a local dataset by discovering new sources by following links between documents.
For this, an iterator-based pipeline <span class="references">[<a href="#ref-13">13</a>]</span> was introduced
that allows query execution to take place without having to wait until all links have been followed.</p>

        <p>Since query execution happens in parallel with source discovery in LTQP,
traditional query optimization algorithms that happen before query execution using statistics of the dataset can not be used,
as those statistics are not known yet.
To cope with this problem, a zero-knowledge query planning technique <span class="references">[<a href="#ref-14">14</a>]</span>
was introduced that orders triple patterns in a query based on several link traversal-specific heuristics.</p>

        <p>In practise, the number of links that could be followed within the Web of Linked Data can become very large.
In the worst case, a single query could require traversing the whole Web, which is not feasible.
Therefore, the formal LTQP model <span class="references">[<a href="#ref-12">12</a>]</span> has the option to configure different reachability criteria,
which are different strategies for deciding which links to follow, each leading to different semantics of query result completeness.
These reachability criteria are the following:</p>

        <dl>
          <dt>cNone</dt>
          <dd>No links are followed</dd>
          <dt>cMatch</dt>
          <dd>Only those links in discovered triples are followed if those triples match with a triple pattern within the query.</dd>
          <dt>cAll</dt>
          <dd>All links are followed</dd>
        </dl>

        <p>Context-based semantics <span class="references">[<a href="#ref-15">15</a>]</span> is an extension of these reachability semantics
that was introduced to be able to cope with property path expressions in the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/">SPARQL 1.1 language</a> <span class="references">[<a href="#ref-16">16</a>]</span>.
Furthermore, next to query-driven reachability, <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.bartbogaerts.eu/articles/2021/005-RuleML-GuidedLink-SubwebSpec/SubwebSpecifications.pdf">another extension</a> <span class="references">[<a href="#ref-17">17</a>]</span> of the LTQP model introduces
the ability for data publishers to express which links should be followed.</p>

        <p>Next to filtering links via different reachability semantics,
a second methodology for improving query result arrival times is through <em>link prioritization</em> <span class="references">[<a href="#ref-18">18</a>]</span>.
However, existing techniques are based on heuristics, which only sometimes result in faster query results compared to no prioritization.</p>

        <p>Even though multiple query languages <span class="references">[<a href="#ref-19">19</a>, <a href="#ref-20">20</a>, <a href="#ref-21">21</a>]</span> have been introduced specifically for LTQP,
its SPARQL-based execution model <span class="references">[<a href="#ref-22">22</a>]</span> is still the most widely used.
Since SPARQL is the only language among these that is a standard, and the fact that it is more widely known and supported by different tools,
we make use of it within this work.
Nevertheless, the concepts within this work can be applied to other languages as well.</p>

        <p>LTQP is related to the idea of SQL-based query execution over the Web <span class="references">[<a href="#ref-23">23</a>, <a href="#ref-24">24</a>]</span>.
However, while LTQP considers the Web of Linked Data a large database using the RDF data model,
these SQL-based approaches over the Web focus on querying attributes or content within Web pages.
Furthermore, LTQP is also related to the concept of focused crawling <span class="references">[<a href="#ref-25">25</a>, <a href="#ref-26">26</a>]</span>,
where crawlers search for Web pages of specific topics to populate a local database or index.
Focus crawling techniques are however designed to run as a preprocessing step <em>before</em> query execution,
while LTQP traverses documents <em>during</em> query execution.</p>

        <h3 id="link-traversal-benchmarks">Link Traversal Benchmarks</h3>

        <p>Aside from the lack of reusable link traversal query engines,
there is also a lack of easily reusable benchmarks for evaluation the performance of link traversal query engines.
According to a recent survey of Linked Data querying approaches <span class="references">[<a href="#ref-27">27</a>]</span>,
<em>“there are no well-defined and well-understood benchmarks to test Linked Data query processing systems”</em>.
Nevertheless, there has been work that provide a foundation onto which benchmarks may be built.</p>

        <p>QWalk <span class="references">[<a href="#ref-28">28</a>]</span> is a methodology for building a large set of queries based on random walks through an existing dataset.
The output of this methodology is a set of Basic Graph Patterns that crosses through various documents through dereferenceable links.
QWalk has been designed to be executed on the actual Web, to evaluate uncontrolled environments.
Due this this, most of the queries generated by the authors make use of links that have gone dead by now,
which makes these queries unsuitable for a reliable and reusable benchmark.
Furthermore, the authors propose making use of queries from existing benchmarks
such as FedBench <span class="references">[<a href="#ref-29">29</a>]</span> and DBpedia SPARQL Benchmark <span class="references">[<a href="#ref-30">30</a>]</span> for execution over the actual Web.
Unfortunately, these also lead to inconsistent and non-reproducible experimental results,
which makes them unsuitable for reliable link traversal benchmarking.
In contrast, the benchmark we propose makes use of a closed environment that is in full control of the experimenter.</p>

        <p>WODSim <span class="references">[<a href="#ref-31">31</a>]</span> is an tool that accepts an RDF dataset as input,
and is able to simulate a Web of Linked Data documents.
For each triple in the dataset, it can either place the triple inside the Linked Data document(s)
identified by the triple’s subject, object, or both.
While this tool is beneficial for running experiments in a reproducible manner,
it does not ship with a standard dataset, which makes is less convenient for reusability.
Our benchmark builds on top of the WODSim approach for fragmenting triples into documents,
and also provides more advanced fragmentation strategies.
Furthermore, it ships with a standard dataset for more convenient usage.</p>

        <p>Aside from these approaches, evaluation of link traversal engines
is usually done via hand crafted queries <span class="references">[<a href="#ref-22">22</a>, <a href="#ref-32">32</a>, <a href="#ref-14">14</a>, <a href="#ref-33">33</a>]</span>.</p>

      </div>
</section>

  <section id="solid" inlist="" rel="schema:hasPart" resource="#solid">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">The Solid Ecosystem</h2>

        <p>In this section, we provide an analysis of the structural properties within the Solid ecosystem
that are relevant for query execution.
We first start by explaining the concept of data vaults and its implications on applications.
Next, we explain the WebID, which is used for identifying users.
Then, we discuss the Solid type index that improves data discovery.
Finally, we list requirements for enabling query execution within the Solid ecosystem.</p>

        <h3 id="data-vault">Data Vault</h3>

        <p>The primary element within the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://solidproject.org/TR/protocol">Solid protocol</a> <span class="references">[<a href="#ref-34">34</a>]</span> is
the data vault (also known as <em>data pod</em>), is a user-owned space in which any kind of data can be stored.
Users can choose where and how their vault is stored,
by either <a property="schema:citation http://purl.org/spar/cito/cites" href="https://github.com/CommunitySolidServer/CommunitySolidServer">hosting it themselves</a> <span class="references">[<a href="#ref-35">35</a>]</span>,
or by obtaining service-provided space by <a property="schema:citation http://purl.org/spar/cito/cites" href="https://docs.inrupt.com/pod-spaces/">a company</a> <span class="references">[<a href="#ref-36">36</a>]</span> or <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.vlaanderen.be/digitaal-vlaanderen/het-vlaams-datanutsbedrijf/the-flemish-data-utility-company">government</a> <span class="references">[<a href="#ref-37">37</a>]</span>.
Data vaults are loosely coupled to applications,
where applications must request explicit access to the user for interacting with specific data.
This loose coupling enables different applications to make use of the same data in an interoperable manner.</p>

        <p>Currently, data vaults are primarily file-based, and are exposed on the Web as a REST API
using elements of the <a href="spec:ldp">Linked Data Platform (LDP) specification</a>.
Directories are represented using <em>LDP Basic Containers</em>,
which can contain any number of resources that correspond to RDF or non-RDF documents,
or other nested basic containers.
For the rest of this article, we will only consider the processing RDF documents within vaults.
Resources within vaults can be read by sending HTTP GET requests to their URLs,
with optional content negotiation to return the documents in different RDF serializations.
If the vault supports this, resources can be modified or created using HTTP PATCH and POST requests.
<a href="#example-ldpcontainer">Listing 1</a> shows an example of such a basic container in a data vault that contains one file and two directories.</p>

        <figure id="example-ldpcontainer" class="listing">
<pre><code>@prefix ldp: &lt;http://www.w3.org/ns/ldp#&gt;.
</code><code>
</code><code>&lt;&gt; a ldp:Container, ldp:BasicContainer, ldp:Resource;
</code><code>   ldp:contains &lt;file.ttl&gt;, &lt;posts/&gt;, &lt;profile/&gt;.
</code><code>&lt;file.ttl&gt; a ldp:Resource.
</code><code>&lt;posts/&gt; a ldp:Container, ldp:BasicContainer, ldp:Resource.
</code><code>&lt;profile/&gt; a ldp:Container, ldp:BasicContainer, ldp:Resource.</code></pre>
<figcaption>
            <p><span class="label">Listing 1:</span> Example in the Turtle serialization of a LDP container in a Solid data vault containing one file and two directories.</p>
          </figcaption>
</figure>

        <p>Data vaults are meant to contain not only public data, but also private data.
Therefore, users can configure who can access or modify files within their vault in a fine-grained manner
using techniques such as <a property="schema:citation http://purl.org/spar/cito/cites" href="https://solid.github.io/web-access-control-spec/">ACL</a> <span class="references">[<a href="#ref-38">38</a>]</span> and <a href="spec:acp">ACP</a>.
This configuration is usually done by referring to the <em>WebID</em> of users,
which will be elaborated upon in the next section.</p>

        <h3 id="webid-profile">WebID Profile</h3>

        <p>Any agent (person or organization) within the Solid ecosystem can establish their identity by a URI, called a WebID.
These agents can authenticate themselves using the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://solid.github.io/solid-oidc/">Solid OIDC protocol</a> <span class="references">[<a href="#ref-39">39</a>]</span>,
which is required for authorization during reading and writing of resources behind access control.
The Solid OIDC protocol is fully decentralized, which means that anyone is free to choose or set up their own identity provider.</p>

        <p>According to the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://solid.github.io/webid-profile/">WebID profile specification</a> <span class="references">[<a href="#ref-40">40</a>]</span>,
each WebID URI should be dereferenceable, and return a WebID profile document.
Next to basic information of the agent such as its name and contact details,
this document should contain several links:</p>

        <ul>
          <li>Identity provider to authenticate the WebID.</li>
          <li>Root LDP container of its data vault.</li>
          <li>Public and private type indexes.</li>
        </ul>

        <p>A WebID profile is allowed to be split up into multiple document,
which are referred to each other using the <code>rdfs:seeAlso</code> predicate.
There are more WebID profiles elements, but we omit these due to their irrelevance in this work,
such as the link to the preferences file and notifications inbox.
<a href="#example-webidprofile">Listing 2</a> contains a simplified example of such a WebID profile.</p>

        <figure id="example-webidprofile" class="listing">
<pre><code>@prefix pim: &lt;http://www.w3.org/ns/pim/space#&gt;.
</code><code>@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt;.
</code><code>@prefix solid: &lt;http://www.w3.org/ns/solid/terms#&gt; .
</code><code>
</code><code>&lt;#me&gt; foaf:name &quot;Zulma&quot;;
</code><code>      pim:storage &lt;/&gt;;
</code><code>      solid:oidcIssuer &lt;https://solidcommunity.net/&gt;;
</code><code>      solid:publicTypeIndex &lt;/publicTypeIndex.ttl&gt;.
</code></pre>
<figcaption>
            <p><span class="label">Listing 2:</span> Simplified example of a WebID profile in the Turtle serialization.</p>
          </figcaption>
</figure>

        <h3 id="type-index">Type Index</h3>

        <p>The <a property="schema:citation http://purl.org/spar/cito/cites" href="https://solid.github.io/webid-profile/">Type Index</a> <span class="references">[<a href="#ref-40">40</a>]</span> is a document that enables type-based resource discovery within a vault.
Users may have public or private type indexes, which respectively refer to data that are and are not publicly discoverable.
A type index can contain type registration entries for different classes,
where each registration has a link to resources containing instances of the corresponding class.
For example, <a href="#example-typeindex">Listing 3</a> shows a type index with type registrations for posts and comments,
where the posts entry refers to a single posts file,
and the comments entry refers to a container with multiple comments files.
If an application wants to obtain all posts of a user,
it can do so by finding this type index and following the link within the type index entry that corresponds to the post class.</p>

        <figure id="example-typeindex" class="listing">
<pre><code>@prefix ldp: &lt;http://www.w3.org/ns/ldp#&gt;.
</code><code>@prefix ex: &lt;http://example.org/&gt;.
</code><code>
</code><code>&lt;&gt;
</code><code>  a solid:TypeIndex ;
</code><code>  a solid:ListedDocument.
</code><code>
</code><code>&lt;#ab09fd&gt; a solid:TypeRegistration;
</code><code>  solid:forClass ex:Post;
</code><code>  solid:instance &lt;/public/posts.ttl&gt;.
</code><code>
</code><code>&lt;#bq1r5e&gt; a solid:TypeRegistration;
</code><code>  solid:forClass ex:Comment;
</code><code>  solid:instanceContainer &lt;/public/comments/&gt;.
</code></pre>
<figcaption>
            <p><span class="label">Listing 3:</span> Example of a type index with entries for posts and comments in the Turtle serialization.</p>
          </figcaption>
</figure>

        <h3 id="requirements-for-query-engines">Requirements for query engines</h3>

        <p>Instead of requiring all application developers to reinvent the wheel by manually discovering application-relevant elements within data vaults,
this can be abstracted away behind declarative queries that are to be executed by reusable query engines.
This also makes applications robust against changes or additions within the Solid protocol,
where this only requires changes within the underlying query engine,
as the application’s declarative query can remain unchanged.</p>

        <p>The <a property="schema:citation http://purl.org/spar/cito/cites" href="https://solidproject.org/TR/protocol">Solid protocol</a> <span class="references">[<a href="#ref-34">34</a>]</span> only establishes a minimal set of ground-rules to make data vaults and applications interoperable.
Below, we list the requirements that query agents have if they want to provide query execution over one or more data vaults.</p>

        <p class="todo">Figure of all relevant Solid elements and query as abstraction layer?</p>

        <ol>
          <li>
            <p><strong>Mapping query to a sequence of HTTP requests</strong>:
The query engine MUST have the ability to convert a declarative query into a sequence of one or more HTTP requests within or across data vaults.</p>
          </li>
          <li>
            <p><strong>Discovery and usage of LDP storage</strong>:
When given a link to a WebID profile, the query engine MUST be able discover and follow the <code>pim:storage</code> link to the storage root of the vault.
Additionally, the query engine MUST be able to identify an LDP basic container, and follow (a subset of) links towards the resources within this container.</p>
          </li>
          <li>
            <p><strong>Discovery and usage of type indexes</strong>:
The query engine MUST be able to discover and follow type index links from the WebID profile, and handle (a subset of) the type registration links.</p>
          </li>
          <li>
            <p><strong>Variability of vault structures</strong>:
The query engine SHOULD NOT make assumptions about the location of certain data within specific vaults
without having an explicit and discoverable link path to it, e.g. via LDP storage or type indexes.</p>
          </li>
          <li>
            <p><strong>Authenticated requests</strong>:
To enable queries over private resources, the agent SHOULD be able to authenticate itself to the query engine using its WebID. The query engine can then use the authenticated session on behalf of the user to perform authorized HTTP requests over private resources.</p>
          </li>
        </ol>

        <p>While these requirements apply to both read and write queries,
we will focus on read-only queries for the remainder of this article.
Furthermore, given the Linked Data nature of Solid,
we will focus on queries using the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/">SPARQL query language</a> <span class="references">[<a href="#ref-16">16</a>]</span> for the remainder of this article.
Nevertheless, these concepts can also be applied to write queries and other query languages.</p>

      </div>
</section>

  <section id="benchmark" inlist="" rel="schema:hasPart" resource="#benchmark">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Benchmark</h2>

        <p>In this section, we introduce <em>SolidBench</em>, a benchmark that enables reproducible performance measurements
of different query execution approaches within a decentralized environment.
For this, SolidBench simulates a decentralized Solid environment with corresponding workload.
Hereafter, we start by explaining the design considerations of the benchmark and our use case scenario, after which we introduce an overview of SolidBench.
Next, we zoom in on important details of the benchmark, such as fragmentation of the data and the query workload.</p>

        <h3 id="design-considerations">Design considerations</h3>

        <p>The goal of our benchmark is to simulate a realistic decentralized environment based on the Solid ecosystem,
and provide a realistic workload that simulates a Solid application that reads data from one or more vaults.
To develop this benchmark, we built upon the choke point-based design methodology from the Linked Data Benchmark Council <span class="references">[<a href="#ref-41">41</a>]</span>.</p>

        <p>Based on our analysis of the Solid ecosystem in <a href="#solid">Section 3</a>,
and requirements from similar benchmarks <span class="references">[<a href="#ref-41">41</a>, <a href="#ref-42">42</a>, <a href="#ref-43">43</a>]</span>,
we introduce the following requirements for our benchmark:</p>

        <ol>
          <li><strong>WebIDs</strong>: The dataset should consist of a collection of simulated WebIDs corresponding to people or other entities. Each WebID should refer to one LDP-based storage vault. Each WebID should be represented using a standard RDF serialization.</li>
          <li><strong>Data vaults</strong>: The dataset should consist of a collection of data vaults, each owned by a WebIDs. Each vault should consist of RDF files in any standard RDF serialization, and should be exposed according to the LDP specification.</li>
          <li><strong>Type indexes</strong>: Each WebID should have a link to one or more type indexes, containing type registrations for data contained in the agent’s vault.</li>
          <li><strong>Variability of vaults</strong>: Data should be organized in different ways in different vaults, to simulate different user preferences in how data is organized.</li>
          <li><strong>Scalable dataset</strong>: The dataset should be configurable in size, which should enable an increase in the number of vaults and vault sizes.</li>
          <li><strong>Workload</strong>: The benchmark should provide a workload of queries that evaluate different query operations and data linking structures.</li>
          <li><strong>Metrics</strong>: The benchmark must be able to metrics such as total query execution time, separate query result arrival times, number of HTTP requests, and correctness.</li>
          <li><strong>Configuration</strong>: The benchmark should be configurable in terms of queries and dataset properties, and provide default values for all of these.</li>
        </ol>

        <h3 id="social-network-scenario">Social Network Scenario</h3>

        <p>Since the original purpose of the Solid project was to enable social interactions in a decentralized manner,
the use case scenario our benchmark tackles is that of a social network.
Concretely, different users each have their own data vault, and each user can provide personal details about themselves in their WebID document such as name, city of residence, and birthday.
Next to that, users can express unidirectional knowledge relationships to other users.
Furthermore, users can create posts, or leave comments on other posts.
To stay in line with the ownership model of Solid, each post or comment a user creates, is stored within that user’s data vault.
This means that chains of comments can span across different data vaults.</p>

        <h3 id="solidbench-overview">SolidBench Overview</h3>

        <p>To avoid reinventing the wheel, we build upon the well-established Social Network Benchmark (SNB) <span class="references">[<a href="#ref-43">43</a>, <a href="#ref-44">44</a>]</span>,
which models a social network akin to Facebook, and meets the requirements of our desired use case scenario.</p>

        <p>However, since SNB was designed to evaluate the performance of centralized query engine,
its dataset generator outputs its dataset in a single large file, e.g. serialized as RDF Turtle.
Since our aim is to simulate a decentralized social network,
we introduce a fragmentation layer on top of this generator.
This fragmenter is able to take in any dataset as input,
and provide a fragmented version of this dataset that simulates an interlinked set of Linked Data documents,
inspired by WODSim <span class="references">[<a href="#ref-31">31</a>]</span>.
To simplify evaluation and testing,
we also provide a built-in Web server that can serve the generated data vaults over HTTP using a single command,
which is done using a slimmed-down version of the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://github.com/CommunitySolidServer/CommunitySolidServer">Community Solid Server</a> <span class="references">[<a href="#ref-35">35</a>]</span>.
This server disables authentication and authorization by default,
so that evaluations can focus on the performance of query execution.</p>

        <p>For the query workload, we build upon the <em>interactive</em> workload of SNB,
and extend it with additional queries to cover link-related choke points.
Since the query templates that are produced by the generator of SNB assume a centralized dataset,
we also add a layer on top of these query templates that can transform the queries to correspond to the decentralized dataset.
Related to this, we also provide a tool that can produce validation queries and results to measure the correctness of a system.
Since we focus on read-only queries in this work, we do not consider the write queries of SNB.</p>

        <p>All aspects of this benchmark are <a property="schema:citation http://purl.org/spar/cito/cites" href="https://linkedsoftwaredependencies.github.io/Article-System-Components/">fully configurable using JSON-LD configuration files</a> <span class="references">[<a href="#ref-45">45</a>]</span>,
ranging from fragmentation strategies to properties of query templates.
Furthermore, we incorporate our benchmark into an existing benchmarking system (<em>name omitted due to double-blind review process</em>),
which enables convenient creation and execution of this benchmark with query engines in reproducible manner.</p>

        <p>By default, SolidBench sets the scale factor of the SNB generator to 0.1,
which results in 157.210 files over 1.529 data vaults using the default fragmentation strategy.
In total, there are 3.556.159 triples across all files, with an average of 22,62 triples per file.
Even though this scale can be increased arbitrarily high,
we notice that this default scale can already stress existing LTQP approaches beyond their capabilities.
For more details on properties of this dataset and its schema, we refer to the SNB papers <span class="references">[<a href="#ref-43">43</a>, <a href="#ref-44">44</a>]</span>.</p>

        <!--
157210 files
1529 pods
3556159 triples
3556159/157210=22,62

Counted using:
- find . type -f | wc -l
- ll | wc -l
- find . -type f -exec wc -l {} \; | awk '{total += $1} END{print total}'

Benchmark aspects:
- Generator: SNB+fragmenter: schema and generator for creating datasets at different scales
- 27 query templates covering different chokepoints (19 from SNB interactive and 8 new)
- Tools to execute experiment and measurement of metrics
-->

        <p class="todo">figure with overview of benchmark components</p>

        <p class="todo">Link to anonimized source code</p>

        <p class="todo">Table with all config options? Maybe just in appendix?</p>

        <h3 id="fragmentation">Fragmentation</h3>

        <p>In order to convert the centralized dataset produced by SNB into a decentralized environment,
we provide a tool that can fragment datasets using different fragmentation strategies.
While this tool provides is highly configurable in terms of its strategies using a declarative JSON-LD-based configuration files,
we only summarize its functionality in terms of two fragmentation dimensions.
Finally, we illustrate its functionality by discussing different fragmentation strategies for handling posts and comments within the SNB dataset.
All strategies within this tool are implemented in a streaming manner,
which means that it can handle input datasets of any size,
and the dataset does not have to be loaded fully in memory before it can be processed.</p>

        <p><strong>Fragmentation dimensions</strong></p>

        <p><em>Triple document assignment</em> is the first dimension of fragmentation,
which concerns the task of deciding which triples are placed in what files.
Inspired by WODSim <span class="references">[<a href="#ref-31">31</a>]</span>, we provide subject and object-based approaches,
which respectively place each triple in the file referred to by their subject or object.
These approaches can also be combined to place triples in both files referred to by subject and object.
Additionally, we provide composition-based approaches, using which triples matching certain triple patterns can be assigned to a different approach.</p>

        <p>The second dimension of fragmentation is that of <em>URI rewriting</em>,
in which URIs can be modified to eventually end up in different documents according to the first dimension.
For example, this allows URIs matching a regex to be modified partially,
or certain triples to be appended upon matching with a certain triple pattern.</p>

        <p><strong>Strategies for fragmenting posts and comments</strong></p>

        <p>Based on the two fragmentation dimension discussed above,
our fragmenter can be configured to manage different fragmentation strategies
for posts and comments in the SNB data schema.
While these strategies can be applied to both posts and comments,
we only explain them hereafter in terms of posts:</p>

        <ol>
          <li><strong>Separate</strong>: Each post created by a person is placed in a separate RDF file within that person’s vault.</li>
          <li><strong>Single</strong>: Posts created by a person are placed in a single RDF file within that person’s vault.</li>
          <li><strong>Location-based</strong>: Posts created by a person are placed in files in that person’s vault corresponding to the location at which the post was created.</li>
          <li><strong>Time-based</strong>: Posts created by a person are placed in files in that person’s vault corresponding to the day at which the post was created.</li>
          <li><strong>Composite</strong>: The strategies above are assigned randomly to all persons in the dataset.</li>
        </ol>

        <p>By default, SolidBench makes use of the composite strategy,
which results in fragmentation variance across the different vaults,
which is realistic for the Solid ecosystem.</p>

        <p class="todo">Mention noise</p>

        <p class="todo">Figure with data model (fragmented)?</p>

        <h3 id="workload">Workload</h3>

        <p>As mentioned above, we make use of the <em>interactive</em> workload of SNB,
since these correspond to the workload that social network applications would produce.
We consider other SNB workloads (such as the business intelligence workload) out of scope,
since these perform dataset analytics, which requires access to the whole dataset,
which is not feasible in decentralization environments such as Solid where data can reside behind access control.
Furthermore, we also focus solely on the class of read-only queries due to the scope of this article,
but the concepts can easily be extended towards write queries.</p>

        <p>The SNB interactive workload consists of two classes of query templates: <em>short</em> and <em>complex</em> read queries.
Since these queries cover the choke points related to linking structures only partially,
we add <em>discover</em> query templates as third class.</p>

        <p><strong>Choke points</strong></p>

        <!-- https://arxiv.org/pdf/2001.02299.pdf -->

        <p>Following the choke point-based design methodology <span class="references">[<a href="#ref-41">41</a>]</span>,
the short and complex SNB interactive workloads already cover the majority of the 33 choke points introduced by SNB.
We refer to the SNB specification <span class="references">[<a href="#ref-44">44</a>]</span> for more details
on the correlation of short and complex query templates to these choke points.</p>

        <p>For this work, we introduce an additional category of choke points that are related to the <em>linking structures</em> within data vaults.
These choke points within this category are the following:</p>

        <ul>
          <li><strong>CP L.1: Traversal of 1 hop (1)</strong>: Following one link to one other document.</li>
          <li><strong>CP L.2: Traversal of 1 hop (n)</strong>: Following one link to multiple other document.</li>
          <li><strong>CP L.3: Traversal of 2 hops (1:1)</strong>: Following one link to another document, and one link to another documents.</li>
          <li><strong>CP L.4: Traversal of 2 hops (1:n)</strong>: Following one link to another document, and multiple links to other documents.</li>
          <li><strong>CP L.5: Traversal of 3 hops (n:1:1)</strong>: Following multiple links to other documents, one link from the next document, and one other link.</li>
          <li><strong>CP L.6: Traversal of 3 hops (n:1:n)</strong>: Following multiple links to other documents, one link from the next document, and multiple other link.</li>
          <li><strong>CP L.7: Fragmentation variability in vaults</strong>: Handling the variability of data fragmentation across different data vaults.</li>
          <li><strong>CP L.8: Index delegation</strong>: The potential of deferring subqueries to an index (such as the type index).</li>
          <li><strong>CP L.9: Noise</strong>: The ability to filter out HTTP requests that are irrelevant to the query.</li>
        </ul>

        <p>Since the short and complex query classes only cover these choke points partially,
we introduce the following <em>discover</em> queries dedicated for covering these choke points on linking structures:</p>

        <ul>
          <li>D1: All posts of a person</li>
          <li>D2: All messages of a person</li>
          <li>D3: Top tags in messages from a person</li>
          <li>D4: Top locations in comments from a person</li>
          <li>D5: All IPs a person has messaged from</li>
          <li>D6: All fora a person messaged on</li>
          <li>D7: All moderators in fora a person messaged on</li>
          <li>D8: Other messages created by people that a person likes messages from</li>
        </ul>

        <p class="todo">Add anon link to templates</p>

        <p>The correlation of these discover queries to choke points is summarized in …TODO…</p>

        <figure id="chokepoints-discover" class="table">

          <table>
            <thead>
              <tr>
                <th>Choke Point</th>
                <th>D1</th>
                <th>D2</th>
                <th>D3</th>
                <th>D4</th>
                <th>D5</th>
                <th>D6</th>
                <th>D7</th>
                <th>D8</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>L.1</td>
                <td>✓</td>
                <td>✓</td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
              </tr>
              <tr>
                <td>L.2</td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td>✓</td>
                <td> </td>
                <td> </td>
                <td> </td>
              </tr>
              <tr>
                <td>L.3</td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td>✓</td>
                <td> </td>
                <td> </td>
              </tr>
              <tr>
                <td>L.4</td>
                <td> </td>
                <td> </td>
                <td>✓</td>
                <td>✓</td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
              </tr>
              <tr>
                <td>L.5</td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td>✓</td>
                <td> </td>
              </tr>
              <tr>
                <td>L.6</td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td>✓</td>
              </tr>
              <tr>
                <td>L.7</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
              </tr>
              <tr>
                <td>L.8</td>
                <td>✓</td>
                <td>✓</td>
                <td> </td>
                <td>✓</td>
                <td> </td>
                <td> </td>
                <td> </td>
                <td>✓</td>
              </tr>
              <tr>
                <td>L.9</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
                <td>✓</td>
              </tr>
            </tbody>
          </table>

          <figcaption>
            <p><span class="label">Table 1:</span> Coverage of choke points on linking structures for discover queries.</p>
          </figcaption>
        </figure>

        <p class="todo">Existing queries in terms of choke points on linking structures?</p>

        <p class="todo">discover queries in terms of 33 existing choke points?</p>

        <p><strong>Query template instantiation</strong></p>

        <p class="todo">Write me</p>

        <p><strong>Metrics</strong></p>

        <p class="todo">Metrics</p>

      </div>
</section>

  <section id="approach" inlist="" rel="schema:hasPart" resource="#approach">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Approach</h2>

        <ul class="todo">
          <li>Cite linktraversalcaching</li>
          <li>We extended cMatch to also work with property paths (define formally?), and extended zero-knowledge planner.</li>
          <li>LDP-based actors</li>
          <li>Type index actor</li>
          <li>Make use of subweb specification formalization to capture LDP and type idx, and make sure to also include formal basis of link traversal</li>
        </ul>

      </div>
</section>

  <section id="evaluation" inlist="" rel="schema:hasPart" resource="#evaluation">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Evaluation</h2>

        <p class="todo">Separate sections with smaller exps with different findings</p>

        <p>Research question: How well does link traversal query processing perform over decentralized environments with structural properties</p>

        <h3 id="only-reachability-semantics-are-insufficient">Only reachability semantics are insufficient</h3>

        <p class="todo">Also show cNone and cAll briefly, but those are either incorrect or too slow, and say we don’t consider them further in this work.</p>

        <p class="todo">Prove this with discover queries comparing just cMatch with cMatch+pim:storage, cMatch+typeidx, cMatch+pim:storage+typeidx</p>

        <p class="todo">But, cMatch is necessary for inter-pod traversal, while LDP and type index can only used for intra-pod querying. (show with a couple of queries and their correctness)</p>

        <h3 id="type-index-is-more-selective-than-ldp-container-traversal">Type index is more selective than LDP container traversal</h3>

        <p class="todo">Show that for queries where type index filtering applies, pim:storage is not necessary, and less links will have to be followed. Because type index is more selective. (pim:storage is a form of index as well! =&gt; use as fallback)
This requires us to make an experiment with pim:storage disabled but type idx not</p>

        <h3 id="zero-knowledge-query-planning-is-ineffective">Zero-knowledge query planning is ineffective</h3>

        <ul class="todo">
          <li>To measure query plan perf: comp with a query that first indexes data locally via construct (measure that time), and than proper query planning =&gt; downside: delays time until first result!
            <ul>
              <li>Implement a link traversal actor that first traverses to find all triples, and then queries afterwards? Or just a simple hacked exp?</li>
            </ul>
          </li>
        </ul>

        <h3 id="live-exploration-is-required-for-heterogeneous-fragmentations">Live exploration is required for heterogeneous fragmentations</h3>

        <p class="todo">Optional: if time left. (we could also just discuss this in conclusions if not time left)
Show that hardcoded data access to specific files is not good, because different vaults have different frag strategies.
Any findings by comparing different frag strategies?</p>
      </div>
</section>

  <section id="conclusions" inlist="" rel="schema:hasPart" resource="#conclusions">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Conclusions</h2>

        <ul class="todo">
          <li>Our results show that link traversal behaves quite different under these assumptions</li>
          <li>Say termination and completeness problems are solved!(?)</li>
          <li>The ability to close the world around solid pods create query opt opoortunities</li>
          <li>Best termination condition is a LIMIT in the query? (but incompat with ORDER BY…)</li>
          <li>Mention need for new datastructures (see ideas note)</li>
          <li>Need for adaptive query planning!</li>
          <li>LDQL not needed, because type idx and ldp give us navigational things (this is not something the developer should have to express, because this is different in different pods!)</li>
          <li>Query containment</li>
        </ul>

      </div>
</section>

</main>

<footer><section>
<h2 id="references">References</h2>
<dl class="references">
  <dt id="ref-1">[1]</dt>
  <dd resource="#webproposal" typeof="schema:CreativeWork">Berners-Lee, T.J.: Information management: A proposal. (1989).</dd>
  <dt id="ref-2">[2]</dt>
  <dd resource="#solid" typeof="schema:Article">Mansour, E., Sambra, A.V., Hawke, S., Zereba, M., Capadisli, S., Ghanem, A., Aboulnaga, A., Berners-Lee, T.: A Demonstration of the Solid platform for Social Web Applications. In: Proceedings of the 25th International Conference Companion on World Wide Web. pp. 223–226 (2016).</dd>
  <dt id="ref-3">[3]</dt>
  <dd resource="#mastodon" typeof="schema:Article">Zignani, M., Gaito, S., Rossi, G.P.: Follow the \enquoteMastodon: Structure and Evolution of a Decentralized Online Social Network. In: Twelfth International AAAI Conference on Web and Social Media (2018).</dd>
  <dt id="ref-4">[4]</dt>
  <dd resource="https://dx.doi.org/10.7717/peerj-cs.387" typeof="schema:Article">Kuhn, T., Taelman, R., Emonet, V., Antonatos, H., Soiland-Reyes, S., Dumontier, M.: Semantic micro-contributions with decentralized nanopublication services. PeerJ Computer Science. (2021). doi:10.7717/peerj-cs.387</dd>
  <dt id="ref-5">[5]</dt>
  <dd resource="#knowledgegraphs" typeof="schema:Article">Hogan, A., Blomqvist, E., Cochez, M., d’Amato, C., Melo, G.de, Gutierrez, C., Kirrane, S., Gayo, J.E.L., Navigli, R., Neumaier, S., others: Knowledge graphs. Synthesis Lectures on Data, Semantics, and Knowledge. 12, 1–257 (2021).</dd>
  <dt id="ref-6">[6]</dt>
  <dd resource="https://www.w3.org/DesignIssues/LinkedData.html" typeof="schema:CreativeWork">Berners-Lee, T.: Linked Data. <a href="https://www.w3.org/DesignIssues/LinkedData.html">https:/​/​www.w3.org/DesignIssues/LinkedData.html</a> (2009).</dd>
  <dt id="ref-7">[7]</dt>
  <dd resource="https://www.w3.org/TR/2013/REC-sparql11-protocol-20130321/" typeof="schema:CreativeWork">Feigenbaum, L., Todd Williams, G., Grant Clark, K., Torres, E.: SPARQL 1.1 Protocol. W3C, <a href="https://www.w3.org/TR/2013/REC-sparql11-protocol-20130321/">https:/​/​www.w3.org/TR/2013/REC-sparql11-protocol-20130321/</a> (2013).</dd>
  <dt id="ref-8">[8]</dt>
  <dd resource="#fedx" typeof="schema:Article">Schwarte, A., Haase, P., Hose, K., Schenkel, R., Schmidt, M.: Fedx: Optimization Techniques for Federated Query Processing on Linked Data. In: International semantic web conference. Springer (2011).</dd>
  <dt id="ref-9">[9]</dt>
  <dd resource="#tpf" typeof="schema:Article">Verborgh, R., Vander Sande, M., Hartig, O., Van Herwegen, J., De Vocht, L., De Meester, B., Haesendonck, G., Colpaert, P.: Triple Pattern Fragments: a low-cost Knowledge Graph Interface for the Web. Journal of Web Semantics. 37, 184–206 (2016).</dd>
  <dt id="ref-10">[10]</dt>
  <dd resource="#hibiscus" typeof="schema:Article">Saleem, M., Ngomo, A.-C.N.: Hibiscus: Hypergraph-based Source Selection for SPARQL Endpoint Federation. In: European semantic web conference. pp. 176–191. Springer (2014).</dd>
  <dt id="ref-11">[11]</dt>
  <dd resource="#linktraversal" typeof="schema:Article">Hartig, O.: An Overview on Execution Strategies for Linked Data Queries. Datenbank-Spektrum. 13, 89–99 (2013).</dd>
  <dt id="ref-12">[12]</dt>
  <dd resource="#linktraversalfoundations" typeof="schema:Article">Hartig, O., Freytag, J.-C.: Foundations of Traversal based Query Execution over Linked Data. In: Proceedings of the 23rd ACM conference on Hypertext and social media. pp. 43–52. ACM (2012).</dd>
  <dt id="ref-13">[13]</dt>
  <dd resource="#linktraversalpipeline" typeof="schema:Article">Hartig, O., Bizer, C., Freytag, J.-C.: Executing SPARQL queries over the web of linked data. In: International semantic web conference. pp. 293–309. Springer (2009).</dd>
  <dt id="ref-14">[14]</dt>
  <dd resource="#zeroknowldgequeryplanning" typeof="schema:Article">Hartig, O.: Zero-knowledge query planning for an iterator implementation of link traversal based query execution. In: Extended Semantic Web Conference. pp. 154–169. Springer (2011).</dd>
  <dt id="ref-15">[15]</dt>
  <dd resource="#linktraversalpropertypaths" typeof="schema:Article">Hartig, O., Pirrò, G.: SPARQL with Property Paths on the Web. Semantic Web. 8, 773–795 (2017).</dd>
  <dt id="ref-16">[16]</dt>
  <dd resource="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/" typeof="schema:CreativeWork">Harris, S., Seaborne, A., Prud’hommeaux, E.: SPARQL 1.1 Query Language. W3C, <a href="https://www.w3.org/TR/2013/REC-sparql11-query-20130321/">https:/​/​www.w3.org/TR/2013/REC-sparql11-query-20130321/</a> (2013).</dd>
  <dt id="ref-17">[17]</dt>
  <dd resource="https://www.bartbogaerts.eu/articles/2021/005-RuleML-GuidedLink-SubwebSpec/SubwebSpecifications.pdf" typeof="schema:Article">Bogaerts, B., Ketsman, B., Zeboudj, Y., Aamer, H., Taelman, R., Verborgh, R.: Link Traversal with Distributed Subweb Specifications. In: Rules and Reasoning: 5th International Joint Conference, RuleML+RR 2021, Leuven, Belgium, September 8 – September 15, 2021, Proceedings (2021).</dd>
  <dt id="ref-18">[18]</dt>
  <dd resource="#linktraversaloptimization" typeof="schema:Article">Hartig, O., Özsu, M.T.: Walking without a Map: Optimizing Response Times of Traversal-based Linked Data Queries (extended version). arXiv preprint arXiv:1607.01046. (2016).</dd>
  <dt id="ref-19">[19]</dt>
  <dd resource="#ldql" typeof="schema:Article">Hartig, O., Pérez, J.: LDQL: A query language for the web of linked data. Journal of Web Semantics. 41, 9–29 (2016).</dd>
  <dt id="ref-20">[20]</dt>
  <dd resource="#nautilod" typeof="schema:Article">Fionda, V., Pirrò, G., Gutierrez, C.: NautiLOD: A formal language for the web of data graph. ACM Transactions on the Web (TWEB). 9, 1–43 (2015).</dd>
  <dt id="ref-21">[21]</dt>
  <dd resource="#ldpath" typeof="schema:Article">Schaffert, S., Bauer, C., Kurz, T., Dorschel, F., Glachs, D., Fernandez, M.: The linked media framework: Integrating and interlinking enterprise media content and data. In: Proceedings of the 8th International Conference on Semantic Systems. pp. 25–32 (2012).</dd>
  <dt id="ref-22">[22]</dt>
  <dd resource="#linktraversalsparql" typeof="schema:Article">Hartig, O.: SPARQL for a Web of Linked Data: Semantics and computability. In: Extended Semantic Web Conference. pp. 8–23. Springer (2012).</dd>
  <dt id="ref-23">[23]</dt>
  <dd resource="#queryingwwwsql" typeof="schema:Article">Mendelzon, A.O., Mihaila, G.A., Milo, T.: Querying the world wide web. In: Fourth International Conference on Parallel and Distributed Information Systems. pp. 80–91. IEEE (1996).</dd>
  <dt id="ref-24">[24]</dt>
  <dd resource="#infogatheringwwww3ql" typeof="schema:Article">Konopnicki, D., Shmueli, O.: Information gathering in the World-Wide Web: the W3QL query language and the W3QS system. ACM Transactions on Database Systems (TODS). 23, 369–410 (1998).</dd>
  <dt id="ref-25">[25]</dt>
  <dd resource="#focusedcrawling" typeof="schema:Article">Chakrabarti, S., Van den Berg, M., Dom, B.: Focused crawling: a new approach to topic-specific Web resource discovery. Computer networks. 31, 1623–1640 (1999).</dd>
  <dt id="ref-26">[26]</dt>
  <dd resource="#focusedcrawlingimproving" typeof="schema:Article">Batsakis, S., Petrakis, E.G.M., Milios, E.: Improving the performance of focused web crawlers. Data &amp; Knowledge Engineering. 68, 1001–1013 (2009).</dd>
  <dt id="ref-27">[27]</dt>
  <dd resource="https://dx.doi.org/10.1007/978-3-319-63962-8_76-1" typeof="schema:CreativeWork">Hartig, O., Hose, K., Sequeda, J.: Linked Data Management. In: Sakr, S. and Zomaya, A. (eds.) Encyclopedia of Big Data Technologies. Springer, Germany (2019). doi:10.1007/978-3-319-63962-8_76-1</dd>
  <dt id="ref-28">[28]</dt>
  <dd resource="#linktraversaldiverse" typeof="schema:Article">Umbrich, J., Hogan, A., Polleres, A., Decker, S.: Link Traversal Querying for a diverse Web of Data. Semantic Web. 6, 585–624 (2015).</dd>
  <dt id="ref-29">[29]</dt>
  <dd resource="#fedbench" typeof="schema:Article">Schmidt, M., Görlitz, O., Haase, P., Ladwig, G., Schwarte, A., Tran, T.: Fedbench: A benchmark suite for federated semantic data query processing. In: International Semantic Web Conference. pp. 585–600. Springer (2011).</dd>
  <dt id="ref-30">[30]</dt>
  <dd resource="#dbpediasparqlbenchmark" typeof="schema:Article">Morsey, M., Lehmann, J., Auer, S., Ngonga Ngomo, A.-C.: DBpedia SPARQL benchmark–performance assessment with real queries on real data. In: International semantic web conference. pp. 454–469. Springer (2011).</dd>
  <dt id="ref-31">[31]</dt>
  <dd resource="#walkingwithoutamap" typeof="schema:Article">Hartig, O., Özsu, M.T.: Walking without a Map: Optimizing Response Times of Traversal-based Linked Data Queries (extended version). arXiv preprint arXiv:1607.01046. (2016).</dd>
  <dt id="ref-32">[32]</dt>
  <dd resource="#linktraversalcaching" typeof="schema:Article">Hartig, O.: How caching improves efficiency and result completeness for querying linked data. In: LDOW (2011).</dd>
  <dt id="ref-33">[33]</dt>
  <dd resource="#sihjoin" typeof="schema:Article">Ladwig, G., Tran, T.: SIHJoin: Querying remote and local linked data. In: Extended Semantic Web Conference. pp. 139–153. Springer (2011).</dd>
  <dt id="ref-34">[34]</dt>
  <dd resource="https://solidproject.org/TR/protocol" typeof="schema:CreativeWork">Capadisli, S., Berners-Lee, T., Verborgh, R., Kjernsmo, K.: Solid Protocol. Solid, <a href="https://solidproject.org/TR/protocol">https:/​/​solidproject.org/TR/protocol</a> (2020).</dd>
  <dt id="ref-35">[35]</dt>
  <dd resource="https://github.com/CommunitySolidServer/CommunitySolidServer" typeof="schema:CreativeWork">Van Herwegen, J., Verborgh, R., Taelman, R., Bosquet, M.: Community Solid Server. <a href="https://github.com/CommunitySolidServer/CommunitySolidServer">https:/​/​github.com/CommunitySolidServer/CommunitySolidServer</a> (2022).</dd>
  <dt id="ref-36">[36]</dt>
  <dd resource="https://docs.inrupt.com/pod-spaces/" typeof="schema:CreativeWork">Inrupt: PodSpaces. <a href="https://docs.inrupt.com/pod-spaces/">https:/​/​docs.inrupt.com/pod-spaces/</a> (2022).</dd>
  <dt id="ref-37">[37]</dt>
  <dd resource="https://www.vlaanderen.be/digitaal-vlaanderen/het-vlaams-datanutsbedrijf/the-flemish-data-utility-company" typeof="schema:CreativeWork">Flanders, D.: The Flemish Data Utility Company. <a href="https://www.vlaanderen.be/digitaal-vlaanderen/het-vlaams-datanutsbedrijf/the-flemish-data-utility-company">https:/​/​www.vlaanderen.be/digitaal-vlaanderen/het-vlaams-datanutsbedrijf/the-flemish-data-utility-company</a> (2022).</dd>
  <dt id="ref-38">[38]</dt>
  <dd resource="https://solid.github.io/web-access-control-spec/" typeof="schema:CreativeWork">Capadisli, S.: Web Access Control. Solid, <a href="https://solid.github.io/web-access-control-spec/">https:/​/​solid.github.io/web-access-control-spec/</a> (2022).</dd>
  <dt id="ref-39">[39]</dt>
  <dd resource="https://solid.github.io/solid-oidc/" typeof="schema:CreativeWork">Coburn, A., Pavlik, elf, Zagidulin, D.: Solid-OIDC. Solid, <a href="https://solid.github.io/solid-oidc/">https:/​/​solid.github.io/solid-oidc/</a> (2022).</dd>
  <dt id="ref-40">[40]</dt>
  <dd resource="https://solid.github.io/webid-profile/" typeof="schema:CreativeWork">Capadisli, S., Berners-Lee, T.: Solid WebID Profile. Solid, <a href="https://solid.github.io/webid-profile/">https:/​/​solid.github.io/webid-profile/</a> (2022).</dd>
  <dt id="ref-41">[41]</dt>
  <dd resource="#ldbc" typeof="schema:Article">Angles, R., Boncz, P., Larriba-Pey, J., Fundulaki, I., Neumann, T., Erling, O., Neubauer, P., Martinez-Bazan, N., Kotsev, V., Toma, I.: The linked data benchmark council: a graph and RDF industry benchmarking effort. ACM SIGMOD Record. 43, 27–31 (2014).</dd>
  <dt id="ref-42">[42]</dt>
  <dd resource="#lingbm" typeof="schema:Article">Cheng, S., Hartig, O.: LinGBM: A Performance Benchmark for Approaches to Build GraphQL Servers. In: Proceedings of the 23rd International Conference on Web Information Systems Engineering (WISE 2022)</dd>
  <dt id="ref-43">[43]</dt>
  <dd resource="#ldbc_snb_interactive" typeof="schema:Article">Erling, O., Averbuch, A., Larriba-Pey, J., Chafi, H., Gubichev, A., Prat, A., Pham, M.-D., Boncz, P.: The LDBC social network benchmark: Interactive workload. In: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data. pp. 619–630 (2015).</dd>
  <dt id="ref-44">[44]</dt>
  <dd resource="#ldbc_snb_details" typeof="schema:Article">Angles, R., Antal, J.B., Averbuch, A., Boncz, P., Erling, O., Gubichev, A., Haprian, V., Kaufmann, M., Pey Josep Lluı́s Larriba, Martı́nez Norbert, others: The LDBC social network benchmark. arXiv preprint arXiv:2001.02299. (2020).</dd>
  <dt id="ref-45">[45]</dt>
  <dd resource="https://linkedsoftwaredependencies.github.io/Article-System-Components/" typeof="schema:Article">Taelman, R., Van Herwegen, J., Vander Sande, M., Verborgh, R.: Components.js: Semantic Dependency Injection. Semantic Web Journal. (2022).</dd>
</dl>
</section>
</footer>

</div>



</body>
</html>
